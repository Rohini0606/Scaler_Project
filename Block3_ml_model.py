# -*- coding: utf-8 -*-
"""Block 3 ML modelling.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F7EXvrYTanFtWVUk8oBrlKxyS88HnVWw
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder, PowerTransformer
from sklearn.cluster import KMeans
#from category_encoders import TargetEncoder
from sklearn.linear_model import LogisticRegression, LinearRegression
import scipy.stats as stats
from sklearn.preprocessing import MinMaxScaler
from sklearn.neighbors import KNeighborsRegressor
from scipy.stats import shapiro, zscore, boxcox
from sklearn.metrics import mean_squared_error
import statsmodels.api as sm

df = pd.read_csv("insurance.csv")

df.head()

df.info()

df.describe()

sns.histplot(df['PremiumPrice'], bins=10, kde=True, color='salmon', edgecolor='black')
plt.xlabel('Premium Price')
plt.ylabel('Frequency')
plt.title('Histogram of Premium Price')

# Adjust layout
plt.tight_layout()
plt.show()

"""**Observation: Data is not normally distributed. Need to convert it to Normal distribution**"""

#Different techinques to convert a random distribution to Normal
# Log transformation
df['log_premium_price'] = np.log(df['PremiumPrice'])

# Square root transformation
df['sqrt_premium_price'] = np.sqrt(df['PremiumPrice'])

# Box-Cox transformation
df['boxcox_premium_price'], fitted_lambda = boxcox(df['PremiumPrice'])

# Yeo-Johnson transformation
pt = PowerTransformer(method='yeo-johnson')
df['yeojohnson_premium_price'] = pt.fit_transform(df[['PremiumPrice']])

# Z-score normalization
df['zscore_premium_price'] = zscore(df['PremiumPrice'])

# Check the distribution visually
transformations = ['PremiumPrice','log_premium_price', 'sqrt_premium_price', 'boxcox_premium_price','yeojohnson_premium_price', 'zscore_premium_price']
plt.figure(figsize=(12, 8))
for i, col in enumerate(transformations):
    plt.subplot(3, 2, i + 1)
    plt.hist(df[col], bins=10, edgecolor='k')
    plt.title(col)

plt.tight_layout()
plt.show()

# Check the normality using Q-Q plot
plt.figure(figsize=(12, 8))
for i, col in enumerate(transformations):
    plt.subplot(3, 2, i + 1)
    stats.probplot(df[col], dist="norm", plot=plt)
    plt.title(f'Q-Q Plot of {col}')

plt.tight_layout()
plt.show()

# Check the normality using Shapiro-Wilk Test
for col in transformations:
    stat, p = shapiro(df[col])
    print(f'Shapiro-Wilk Test for {col}: Statistics={stat:.3f}, p={p:.9f}')
    if p > 0.05:
        print(f'Sample looks Gaussian (fail to reject H0) for {col}')
    else:
        print(f'Sample does not look Gaussian (reject H0) for {col}')

"""Though the Shapiro test shows that boxcox, log, zscore, johnson techniques chould not convert it to Gaussian, we can replace Target variable with one of these and test the model performance."""

sns.histplot(df['log_premium_price'], bins=6, kde=True, color='salmon', edgecolor='black')
plt.xlabel('Premium Price')
plt.ylabel('Frequency')
plt.title('Histogram of Premium Price')

# Adjust layout
plt.tight_layout()
plt.show()

x = df

x.head()

y = df['log_premium_price']

x = df.drop(columns = ['PremiumPrice','log_premium_price','boxcox_premium_price',	'yeojohnson_premium_price',	'zscore_premium_price','sqrt_premium_price'])

x.head()

model =LinearRegression()

from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures

poly = PolynomialFeatures(degree=2)
X_poly = poly.fit_transform(x)

X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=1)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_Scaled=scaler.fit_transform(X_test)

model.fit(X_train_scaled,y_train)

model.coef_

model.intercept_

model.score(X_train_scaled, y_train)

y_pred = model.predict(X_test_Scaled)
mse = mean_squared_error(y_test, y_pred)
print(f"Mean Squared Error: {mse}")

"""Validating the model

"""

# Calculate residuals
residuals = y_test - y_pred

# Plot residuals
plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
sns.histplot(residuals, kde=True, color='skyblue', edgecolor='black')
plt.xlabel('Residuals')
plt.title('Histogram of Residuals')

plt.subplot(1, 2, 2)
sm.qqplot(residuals, line ='45')
plt.title('Q-Q Plot of Residuals')

plt.tight_layout()
plt.show()

stat, p = shapiro(residuals)
print(f'Shapiro-Wilk Test Statistic: {stat}')
print(f'p-value: {p}')

"""pvalue < alpha, Reject null hypothesis which says that the distribution is not Gaussian.

Distribution is Gaussian.
"""

import pickle

pickle_out = open("Prediction.pkl", mode = "wb")
pickle.dump(model, pickle_out)
pickle_out.close()

